#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FFT TabanlÄ± Veri Ã–n Ä°ÅŸleme
==========================
Bu script, Raw EEG'den FFT ile hesaplanmÄ±ÅŸ bant deÄŸerlerini kullanarak
model eÄŸitimi iÃ§in veri hazÄ±rlar.

Ã–NEMLÄ°: Event Id sÃ¼tunundaki START (33025) ve END (33024) iÅŸaretleri
kullanÄ±larak sadece aktif (dÃ¼ÅŸÃ¼nme) bÃ¶lgeleri alÄ±nÄ±r.

Veri kaynaÄŸÄ±: ./data/ (convert_raw_to_fft.py Ã§Ä±ktÄ±sÄ±)
Ã‡Ä±ktÄ±: X_fft.npy, y_fft.npy, label_map_fft.json
"""

import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import json
from pathlib import Path

# Veri dizinleri
SCRIPT_DIR = Path(__file__).parent
# FiltrelenmiÅŸ veri varsa onu kullan, yoksa normal veriyi
DATA_DIR_FILTERED = SCRIPT_DIR / "data_filtered"
DATA_DIR_NORMAL = SCRIPT_DIR / "data"
DATA_DIR = DATA_DIR_FILTERED if DATA_DIR_FILTERED.exists() else DATA_DIR_NORMAL
OUTPUT_DIR = SCRIPT_DIR  # fft_model/

# EEG Ã¶zellikleri (FFT ile hesaplanmÄ±ÅŸ)
EEG_FEATURES = ["Electrode", "Delta", "Theta", "Low Alpha", "High Alpha", 
                "Low Beta", "High Beta", "Low Gamma", "Mid Gamma"]

# Pencere ayarlarÄ±
WINDOW_SIZE = 128  # Orijinal modelle aynÄ±
OVERLAP = 64       # %50 overlap

# Event iÅŸaretleri
START_EVENT = 33025
END_EVENT = 33024


def load_csv_files():
    """
    fft_model/data klasÃ¶rÃ¼ndeki tÃ¼m CSV dosyalarÄ±nÄ± yÃ¼kle
    """
    csv_files = []
    
    if not DATA_DIR.exists():
        print(f"âŒ Veri dizini bulunamadÄ±: {DATA_DIR}")
        return csv_files
    
    # Kategori klasÃ¶rlerini tara
    for category_dir in sorted(DATA_DIR.iterdir()):
        if not category_dir.is_dir():
            continue
        
        class_name = category_dir.name
        
        # Kategori dÃ¼zeltmeleri
        if class_name == "asagÄ±":
            class_name = "aÅŸaÄŸÄ±"
        
        # Bu kategorideki CSV dosyalarÄ±nÄ± yÃ¼kle
        for csv_file in sorted(category_dir.glob("*.csv")):
            try:
                df = pd.read_csv(csv_file)
                csv_files.append((csv_file.name, df, class_name))
                print(f"âœ… YÃ¼klendi: {category_dir.name}/{csv_file.name} â†’ {class_name} ({len(df)} satÄ±r)")
            except Exception as e:
                print(f"âŒ Hata ({csv_file.name}): {e}")
    
    return csv_files


def extract_active_segments(df):
    """
    Event Id sÃ¼tunundaki START/END iÅŸaretlerini kullanarak
    sadece aktif (dÃ¼ÅŸÃ¼nme) bÃ¶lgelerini Ã§Ä±kar
    
    Returns:
        list of DataFrames: Aktif segmentler
    """
    active_segments = []
    
    if 'Event Id' not in df.columns:
        # Event Id yoksa tÃ¼m veriyi dÃ¶ndÃ¼r (eski davranÄ±ÅŸ)
        print("      âš  Event Id sÃ¼tunu yok, tÃ¼m veri kullanÄ±lacak")
        return [df]
    
    # Event Id'leri sayÄ±sal deÄŸerlere Ã§evir (NaN'larÄ± 0 yap)
    event_ids = pd.to_numeric(df['Event Id'], errors='coerce').fillna(0).astype(int)
    
    # BaÅŸlangÄ±Ã§ ve bitiÅŸ indekslerini bul
    start_indices = df.index[event_ids == START_EVENT].tolist()
    end_indices = df.index[event_ids == END_EVENT].tolist()
    
    if not start_indices:
        print("      âš  START iÅŸareti bulunamadÄ±, tÃ¼m veri kullanÄ±lacak")
        return [df]
    
    print(f"      ğŸ“ {len(start_indices)} START, {len(end_indices)} END iÅŸareti bulundu")
    
    # Her START iÃ§in en yakÄ±n END'i bul
    for start_idx in start_indices:
        # Bu START'tan sonraki END'leri bul
        valid_ends = [end for end in end_indices if end > start_idx]
        if valid_ends:
            end_idx = valid_ends[0]
            # START ve END arasÄ±ndaki veriyi al
            segment = df.iloc[start_idx:end_idx+1].copy()
            if len(segment) > WINDOW_SIZE:
                active_segments.append(segment)
                print(f"      âœ… Aktif segment: {len(segment)} satÄ±r ({len(segment)/512:.1f}s)")
    
    if not active_segments:
        print("      âš  Aktif segment bulunamadÄ±")
    
    return active_segments


def create_windows(df):
    """
    DataFrame'den sliding window'lar oluÅŸtur
    """
    # Sadece EEG Ã¶zelliklerini al
    available_features = [f for f in EEG_FEATURES if f in df.columns]
    data = df[available_features].values
    data = np.nan_to_num(data, nan=0.0)
    
    windows = []
    step = WINDOW_SIZE - OVERLAP
    
    for i in range(0, len(data) - WINDOW_SIZE + 1, step):
        window = data[i:i + WINDOW_SIZE]
        windows.append(window)
    
    return np.array(windows) if windows else np.array([])


def process_all_data(csv_files):
    """
    TÃ¼m CSV dosyalarÄ±nÄ± iÅŸle - sadece aktif bÃ¶lgeleri kullan
    """
    all_windows = []
    all_labels = []
    label_map = {}
    current_label = 0
    
    for filename, df, class_name in csv_files:
        print(f"\n   ğŸ“‚ {filename} iÅŸleniyor...")
        
        # SÄ±nÄ±f etiketini ata
        if class_name not in label_map:
            label_map[class_name] = current_label
            current_label += 1
        
        label = label_map[class_name]
        
        # Aktif segmentleri Ã§Ä±kar
        active_segments = extract_active_segments(df)
        
        # Her segment iÃ§in pencereler oluÅŸtur
        total_windows = 0
        for segment in active_segments:
            windows = create_windows(segment)
            if len(windows) > 0:
                all_windows.append(windows)
                all_labels.extend([label] * len(windows))
                total_windows += len(windows)
        
        if total_windows > 0:
            print(f"      ğŸ“Š Toplam: {total_windows} pencere â†’ etiket {label} ({class_name})")
    
    if all_windows:
        X = np.vstack(all_windows)
        y = np.array(all_labels)
        return X, y, label_map
    else:
        return None, None, None


def normalize_data(X):
    """
    StandardScaler ile normalizasyon
    """
    print("\nğŸ“ Normalizasyon uygulanÄ±yor...")
    
    original_shape = X.shape
    X_flat = X.reshape(X.shape[0], -1)
    
    scaler = StandardScaler()
    X_normalized_flat = scaler.fit_transform(X_flat)
    X_normalized = X_normalized_flat.reshape(original_shape)
    
    print(f"   Mean: {X_normalized.mean():.6f}")
    print(f"   Std:  {X_normalized.std():.6f}")
    
    # Scaler parametrelerini kaydet
    scaler_params = {
        'mean': scaler.mean_.tolist(),
        'std': scaler.scale_.tolist(),
        'feature_names': EEG_FEATURES,
        'window_size': WINDOW_SIZE
    }
    
    with open(OUTPUT_DIR / 'scaler_params_fft.json', 'w') as f:
        json.dump(scaler_params, f, indent=2)
    print(f"   âœ… Scaler parametreleri kaydedildi: scaler_params_fft.json")
    
    return X_normalized, scaler


def visualize_comparison(X, y, label_map):
    """
    SÄ±nÄ±flar arasÄ± karÅŸÄ±laÅŸtÄ±rma gÃ¶rselleÅŸtirmesi
    """
    fig, axes = plt.subplots(3, 3, figsize=(15, 12))
    fig.suptitle('FFT TabanlÄ± EEG BantlarÄ± - SÄ±nÄ±f KarÅŸÄ±laÅŸtÄ±rmasÄ±', fontsize=14)
    
    reverse_label_map = {v: k for k, v in label_map.items()}
    colors = ['blue', 'green', 'red']
    
    for idx, feature_name in enumerate(EEG_FEATURES):
        row = idx // 3
        col = idx % 3
        ax = axes[row, col]
        
        for label_idx, color in enumerate(colors):
            if label_idx >= len(label_map):
                continue
            
            label_name = reverse_label_map[label_idx]
            mask = y == label_idx
            
            # Bu sÄ±nÄ±fa ait tÃ¼m pencerelerin ortalamasÄ±
            class_data = X[mask, :, idx]
            mean_signal = class_data.mean(axis=0)
            std_signal = class_data.std(axis=0)
            
            x = np.arange(WINDOW_SIZE)
            ax.plot(x, mean_signal, color=color, label=label_name, linewidth=1.5)
            ax.fill_between(x, mean_signal - std_signal, mean_signal + std_signal, 
                          color=color, alpha=0.2)
        
        ax.set_title(feature_name)
        ax.grid(True, alpha=0.3)
        ax.legend(fontsize=8)
    
    plt.tight_layout()
    plt.savefig(OUTPUT_DIR / 'fft_class_comparison.png', dpi=150)
    print(f"\n   âœ… GÃ¶rselleÅŸtirme kaydedildi: fft_class_comparison.png")
    plt.close()


def save_data(X, y, label_map):
    """
    Ä°ÅŸlenmiÅŸ veriyi kaydet
    """
    np.save(OUTPUT_DIR / 'X_fft.npy', X)
    np.save(OUTPUT_DIR / 'y_fft.npy', y)
    
    with open(OUTPUT_DIR / 'label_map_fft.json', 'w', encoding='utf-8') as f:
        json.dump(label_map, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Veriler kaydedildi:")
    print(f"   âœ… X_fft.npy: {X.shape}")
    print(f"   âœ… y_fft.npy: {y.shape}")
    print(f"   âœ… label_map_fft.json: {label_map}")


def main():
    print("\n" + "=" * 60)
    print("ğŸ§  FFT TABANLI VERÄ° Ã–N Ä°ÅLEME")
    print("=" * 60)
    print(f"ğŸ“‚ Veri dizini: {DATA_DIR}")
    print(f"ğŸ“‚ Ã‡Ä±ktÄ± dizini: {OUTPUT_DIR}")
    print(f"ğŸ“ Pencere boyutu: {WINDOW_SIZE}")
    print(f"ğŸ“ Overlap: {OVERLAP}")
    
    # CSV dosyalarÄ±nÄ± yÃ¼kle
    print("\nğŸ“¥ CSV dosyalarÄ± yÃ¼kleniyor...")
    csv_files = load_csv_files()
    
    if not csv_files:
        print("\nâŒ CSV dosyasÄ± bulunamadÄ±!")
        return
    
    # Veriyi iÅŸle
    print("\nğŸ”„ Pencereler oluÅŸturuluyor...")
    X, y, label_map = process_all_data(csv_files)
    
    if X is None:
        print("\nâŒ Veri iÅŸleme baÅŸarÄ±sÄ±z!")
        return
    
    # Ä°statistikler
    print("\n" + "=" * 60)
    print("ğŸ“Š VERÄ° Ä°STATÄ°STÄ°KLERÄ°")
    print("=" * 60)
    print(f"Toplam pencere: {len(X)}")
    print(f"Pencere ÅŸekli: {X.shape}")
    print(f"\nğŸ·ï¸  SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
    
    reverse_label_map = {v: k for k, v in label_map.items()}
    for label_idx in sorted(reverse_label_map.keys()):
        label_name = reverse_label_map[label_idx]
        count = np.sum(y == label_idx)
        percentage = (count / len(y)) * 100
        print(f"   {label_name:10s}: {count:5d} pencere ({percentage:5.1f}%)")
    
    # Normalizasyon
    X_normalized, scaler = normalize_data(X)
    
    # GÃ¶rselleÅŸtirme
    visualize_comparison(X_normalized, y, label_map)
    
    # Kaydet
    save_data(X_normalized, y, label_map)
    
    print("\n" + "=" * 60)
    print("âœ… FFT VERÄ° Ã–N Ä°ÅLEME TAMAMLANDI!")
    print("=" * 60)
    print("ğŸ¯ Sonraki adÄ±m: python3 train_model_fft.py")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()

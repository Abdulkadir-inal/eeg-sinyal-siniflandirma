# SÄ±nÄ±f DengesizliÄŸi Analizi

## Soruna TanÄ±klÄ±k

Model "aÅŸaÄŸÄ±" sÄ±nÄ±fÄ±na baskÄ±nlÄ±k gÃ¶steriyordu, hatta tahminler Ã§oÄŸunlukla "aÅŸaÄŸÄ±" Ã§Ä±kÄ±yordu.

### Orijinal Sorun
```
yukarÄ± dosyasÄ±nda: %60 aÅŸaÄŸÄ±, %24 yukarÄ±, %17 araba
asagÄ±  dosyasÄ±nda: %71 aÅŸaÄŸÄ±, %16 yukarÄ±, %13 araba  
araba  dosyasÄ±nda: %72 aÅŸaÄŸÄ±, %21 yukarÄ±, %7 araba
```

## KÃ¶k Nedenleri

### 1. EÄŸitim Verisi DengesizliÄŸi
```
ğŸ“Š Training Seti DaÄŸÄ±lÄ±mÄ± (Augmentation SonrasÄ±):
   yukarÄ±    : aÄŸÄ±rlÄ±k = 0.855 (102352/262676 Ã¶rnek) - % 39.0
   aÅŸaÄŸÄ±     : aÄŸÄ±rlÄ±k = 1.027 (85296/262676 Ã¶rnek)  - % 32.5
   araba     : aÄŸÄ±rlÄ±k = 1.167 (75028/262676 Ã¶rnek)  - % 28.6
```

**AÃ§Ä±klama**: "yukarÄ±" sÄ±nÄ±fÄ± daha fazla Ã¶rneÄŸe sahip ama model "aÅŸaÄŸÄ±"ya baskÄ±nlÄ±k gÃ¶steriyordu.

### 2. Loss Function Problemi
**Orijinal kodda**:
```python
criterion = nn.CrossEntropyLoss()  # SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± yok!
```

**Sorun**: CrossEntropyLoss varsayÄ±lan olarak tÃ¼m sÄ±nÄ±flarÄ± eÅŸit tedavi eder. Dengesiz veri Ã¼zerinde, sÄ±k gÃ¶rÃ¼len sÄ±nÄ±f (burada "aÅŸaÄŸÄ±") model tarafÄ±ndan fazla tercih edilir.

### 3. Veri Ã–n Ä°ÅŸleme FarklÄ±lÄ±klarÄ±
Training sÄ±rasÄ±nda veri ÅŸu adÄ±mlardan geÃ§er:
1. FFT bant gÃ¼Ã§leri (8 Ã¶zellik)
2. Log transform: `log1p(abs(x))`
3. TÃ¼retilmiÅŸ Ã¶zellikler eklenir (7 tane daha â†’ 15 toplam)
4. StandardScaler normalizasyon (15 Ã¶zelliÄŸe uygun)

Tahmin yapÄ±lÄ±rken ham CSV verileri kullanÄ±lÄ±rsa:
- Log transform uygulanmadÄ±ysa
- TÃ¼retilmiÅŸ Ã¶zellikler hesaplanmadÄ±ysa
- Scaler 15 Ã¶zellik bekliyor ama 8 verilmiÅŸse

â†’ **YanlÄ±ÅŸ normalizasyon = YanlÄ±ÅŸ tahminler**

## Ã‡Ã¶zÃ¼mler UygulandÄ±

### 1. Class Weight Loss Function (âœ… YapÄ±ldÄ±)
```python
# SÄ±nÄ±f aÄŸÄ±rlÄ±klarÄ± hesapla
unique, counts = np.unique(y_train_aug, return_counts=True)
total = len(y_train_aug)
class_weights = []
for i in range(num_classes):
    weight = total / (num_classes * count[i])
    class_weights.append(weight)

# Loss function'a ekle
criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights))
```

**Etki**: 
- Nadir sÄ±nÄ±flar (araba) daha fazla aÄŸÄ±rlÄ±k alÄ±r
- Model tÃ¼m sÄ±nÄ±flarÄ± dengeli Ã¶ÄŸrenir
- Epoch 40'ta 96.76% validation accuracy

### 2. Veri Ã–n Ä°ÅŸleme Kontrol Listesi
Dosya modunda tahmin yapÄ±lÄ±rken:

âœ… **Raw FFT bant gÃ¼Ã§leri yÃ¼klenir**
```python
fft_data = df[['Delta', 'Theta', 'Low Alpha', ...]].values
```

âœ… **Log transform uygulanÄ±r**
```python
features = np.log1p(np.abs(features))
```

âœ… **TÃ¼retilmiÅŸ Ã¶zellikler eklenir** (7 tane daha)
```python
alpha_total = low_alpha + high_alpha
beta_total = low_beta + high_beta
...
engagement = beta_total / (alpha_total + theta + eps)
# Extended: 15 Ã¶zellik
```

âœ… **StandardScaler normalizasyon** (15 Ã¶zellik iÃ§in eÄŸitilmiÅŸ)
```python
sequence = scaler.transform(sequence)  # 15 Ã¶zellik ile
```

### 3. Epoch Optimizasyon
- Orijinal: 100 epoch
- DÃ¼zeltme: 50 epoch (class weights daha hÄ±zlÄ± yakÄ±nsar)
- Early stopping: best val_acc Epoch 40'ta (96.76%)

## Test SonuÃ§larÄ±

### Dosya Modu - DoÄŸru Ã–n Ä°ÅŸleme ile
```
yukarÄ± klasÃ¶rÃ¼nde test:
  aÅŸaÄŸÄ± :  59.6%  (hala baskÄ±n)
  yukarÄ±:  40.4%  (dÃ¶nemirli tahminler)
```

**Not**: Raw veri formatÄ± "aÅŸaÄŸÄ±"ya baskÄ±nlÄ±k gÃ¶sterebilir. Bunun nedenleri:
1. Ä°nsan fizyolojisi: BaÅŸÄ±nda EEG cihazÄ± takÄ±lÄ±yken "aÅŸaÄŸÄ±" hareketi daha stabil ve net sinyal Ã¼retiyor olabilir
2. Sinyal kalitesi: "yukarÄ±" hareketi sÄ±rasÄ±nda cihaz kayabilir (daha gÃ¼rÃ¼ltÃ¼lÃ¼)
3. Veri toplama: "aÅŸaÄŸÄ±" hareketinde daha fazla Ã¶rnek toplanmÄ±ÅŸ olabilir

## GeliÅŸim YapÄ±labilecek Alanlar

### 1. Daha GÃ¼Ã§lÃ¼ Class Balancing
- Weighted Random Sampler (over/under sampling)
- SMOTE (synthetic data generation)
- Focal Loss (hard examples'a daha fazla aÄŸÄ±rlÄ±k)

### 2. Veri ArtÄ±rma
```python
# Zaten yapÄ±lan
- Gaussian noise
- Random scaling
- Time shift

# YapÄ±labilecek
- Mixup (iki Ã¶rneÄŸi karÄ±ÅŸtÄ±r)
- SpecAugment (band'larÄ± maskeĞ»Ğµ)
- Ensemble (farklÄ± modellerle)
```

### 3. Model Architecture
- Attention mekanizmasÄ± (hangi bantlara daha Ã§ok dikkat et)
- Multi-task learning (sÄ±nÄ±f + bant gÃ¼Ã§leri prediction)
- Confidence calibration

### 4. Cross-Validation
```python
# Åu anda
train/val: 80/20 split

# YapÄ±labilecek
StratifiedKFold (k=5) - her fold'da sÄ±nÄ±f dengesi kontrol edilir
```

## Ã–zet

âœ… **Class weights uygulandÄ±** â†’ Model tÃ¼m sÄ±nÄ±flarÄ± dengeli Ã¶ÄŸrenir
âœ… **Validation accuracy: 96.76%** (Epoch 40)
âš ï¸ **Test verisi hala "aÅŸaÄŸÄ±"ya baskÄ±nlÄ±k gÃ¶sterebilir** â†’ Fizyolojik/teknik nedenleri olabilir
ğŸ¯ **Ä°leri adÄ±m**: Live capture problemleri Ã§Ã¶zÃ¼ldÃ¼kten sonra gerÃ§ek veri ile yeniden test et

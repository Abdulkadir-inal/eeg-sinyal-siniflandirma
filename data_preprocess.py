#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EEG Veri Ã–n Ä°ÅŸleme - 4 SÄ±nÄ±f Sistemi
GÃœNCELLEME (27 Ekim 2025): araba, yukarÄ±, aÅŸaÄŸÄ±, boÅŸ sÄ±nÄ±flarÄ± iÃ§in
- START/END iÅŸaretleri arasÄ±ndaki bÃ¶lgeler â†’ komut sÄ±nÄ±flarÄ± (araba, yukarÄ±, aÅŸaÄŸÄ±)
- START/END iÅŸaretleri dÄ±ÅŸÄ±ndaki bÃ¶lgeler â†’ "boÅŸ" sÄ±nÄ±fÄ±
"""

import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import json

# Veri dizinleri - hem proje klasÃ¶rÃ¼ hem de proje-veri klasÃ¶rÃ¼
DATA_DIRS = [
    "/home/kadir/sanal-makine/python/proje",
    "/home/kadir/sanal-makine/python/proje-veri/araba",
    "/home/kadir/sanal-makine/python/proje-veri/yukarÄ±", 
    "/home/kadir/sanal-makine/python/proje-veri/asagÄ±"
]
OUTPUT_DIR = "/home/kadir/sanal-makine/python/proje"

EEG_FEATURES = ["Electrode", "Delta", "Theta", "Low Alpha", "High Alpha", "Low Beta", "High Beta", "Low Gamma", "Mid Gamma"]
WINDOW_SIZE = 128
OVERLAP = 64
START_EVENT = 33025
END_EVENT = 33024

def load_csv_files(data_dirs):
    """
    Birden fazla dizindeki CSV dosyalarÄ±nÄ± yÃ¼kle
    Her dosyanÄ±n hangi sÄ±nÄ±fa ait olduÄŸunu dosya adÄ±ndan veya dizinden belirle
    Test dosyalarÄ±nÄ± (test_*.csv) hariÃ§ tut
    """
    csv_files = []
    for data_dir in data_dirs:
        if not os.path.exists(data_dir):
            continue
        for filename in os.listdir(data_dir):
            # Test dosyalarÄ±nÄ± atla
            if filename.startswith("test_") or not filename.endswith(".csv"):
                continue
                
            filepath = os.path.join(data_dir, filename)
            try:
                df = pd.read_csv(filepath)
                # Dosya adÄ±ndan veya dizin adÄ±ndan sÄ±nÄ±f bilgisini al
                if "araba" in filename.lower() or "araba" in data_dir.lower():
                    class_name = "araba"
                elif "yukarÄ±" in filename.lower() or "yukarÄ±" in data_dir.lower():
                    class_name = "yukarÄ±"
                elif "aÅŸaÄŸÄ±" in filename.lower() or "asagÄ±" in filename.lower() or "asagÄ±" in data_dir.lower():
                    class_name = "aÅŸaÄŸÄ±"
                else:
                    class_name = filename.replace(".csv", "")
                
                csv_files.append((filename, df, class_name))
                print(f"âœ… YÃ¼klendi: {filename} â†’ {class_name} ({len(df)} satÄ±r)")
            except Exception as e:
                print(f"âŒ Hata ({filename}): {e}")
    return csv_files

def extract_segments_with_idle(df):
    """
    START/END iÅŸaretleri arasÄ±ndaki segmentleri ve dÄ±ÅŸÄ±ndaki "boÅŸ" bÃ¶lgeleri ayÄ±r
    
    Returns:
        active_segments: Komut segmentleri (list of DataFrame)
        idle_segments: BoÅŸ bÃ¶lgeler (list of DataFrame)
    """
    active_segments = []
    idle_segments = []
    
    if "Event Id" not in df.columns:
        # Event Id yoksa tÃ¼m veri boÅŸ
        if len(df) > WINDOW_SIZE:
            idle_segments.append(df.copy())
        return active_segments, idle_segments
    
    # BaÅŸlangÄ±Ã§ ve bitiÅŸ indekslerini bul
    start_indices = df[df["Event Id"] == START_EVENT].index.tolist()
    end_indices = df[df["Event Id"] == END_EVENT].index.tolist()
    
    print(f"   ğŸ“ BaÅŸlangÄ±Ã§: {len(start_indices)}, BitiÅŸ: {len(end_indices)}")
    
    # Aktif bÃ¶lgeleri Ã§Ä±kar (START ve END arasÄ±nda)
    active_ranges = []
    for start_idx in start_indices:
        valid_ends = [end for end in end_indices if end > start_idx]
        if valid_ends:
            end_idx = valid_ends[0]
            segment = df.iloc[start_idx+1:end_idx].copy()
            if len(segment) > 0:
                active_segments.append(segment)
                active_ranges.append((start_idx, end_idx))
                print(f"   âœ… Aktif segment: {len(segment)} satÄ±r")
    
    # BoÅŸ bÃ¶lgeleri Ã§Ä±kar (START/END dÄ±ÅŸÄ±ndaki her ÅŸey)
    if len(active_ranges) == 0:
        # HiÃ§ aktif segment yoksa tÃ¼m veri boÅŸ
        if len(df) > WINDOW_SIZE:
            idle_segments.append(df.copy())
            print(f"   ğŸ’¤ BoÅŸ bÃ¶lge (tÃ¼m veri): {len(df)} satÄ±r")
    else:
        # Ä°lk aktif segmentten Ã¶ncesi
        if active_ranges[0][0] > 0:
            idle_seg = df.iloc[0:active_ranges[0][0]].copy()
            if len(idle_seg) > WINDOW_SIZE:
                idle_segments.append(idle_seg)
                print(f"   ğŸ’¤ BoÅŸ bÃ¶lge (baÅŸlangÄ±Ã§): {len(idle_seg)} satÄ±r")
        
        # Aktif segmentler arasÄ±
        for i in range(len(active_ranges) - 1):
            start = active_ranges[i][1]
            end = active_ranges[i+1][0]
            if end - start > WINDOW_SIZE:
                idle_seg = df.iloc[start:end].copy()
                idle_segments.append(idle_seg)
                print(f"   ğŸ’¤ BoÅŸ bÃ¶lge (ara): {len(idle_seg)} satÄ±r")
        
        # Son aktif segmentten sonrasÄ±
        if active_ranges[-1][1] < len(df):
            idle_seg = df.iloc[active_ranges[-1][1]:].copy()
            if len(idle_seg) > WINDOW_SIZE:
                idle_segments.append(idle_seg)
                print(f"   ğŸ’¤ BoÅŸ bÃ¶lge (son): {len(idle_seg)} satÄ±r")
    
    return active_segments, idle_segments

def extract_segments(df):
    """Eski fonksiyon - sadece aktif segmentleri dÃ¶ndÃ¼r"""
    active_segments, _ = extract_segments_with_idle(df)
    return active_segments

def create_windows(segment):
    data = segment[EEG_FEATURES].values
    data = np.nan_to_num(data, nan=0.0)
    windows = []
    step = WINDOW_SIZE - OVERLAP
    for i in range(0, len(data) - WINDOW_SIZE + 1, step):
        window = data[i:i + WINDOW_SIZE]
        windows.append(window)
    return np.array(windows)

def process_all_data(csv_files, include_idle=False):
    """
    TÃ¼m CSV dosyalarÄ±nÄ± iÅŸle - 3 sÄ±nÄ±f sistemi (araba, yukarÄ±, aÅŸaÄŸÄ±)
    
    Args:
        csv_files: (filename, DataFrame, class_name) tuple'larÄ±nÄ±n listesi
        include_idle: BoÅŸ sÄ±nÄ±fÄ±nÄ± dahil et (varsayÄ±lan: False - BOÅ SINIFI YOK)
    
    Returns:
        X: Ã–zellik matrisi (N, 128, 9)
        y: Etiketler (N,)
        label_map: {'araba': 0, 'yukarÄ±': 1, 'aÅŸaÄŸÄ±': 2}
    """
    all_windows = []
    all_labels = []
    label_map = {}
    current_label = 0
    
    # Ä°lk olarak tÃ¼m komut sÄ±nÄ±flarÄ±nÄ± iÅŸle
    for filename, df, class_name in csv_files:
        print(f"\n{'='*60}")
        print(f"ğŸ“‚ Ä°ÅŸleniyor: {filename} â†’ {class_name}")
        print(f"{'='*60}")
        
        if class_name not in label_map:
            label_map[class_name] = current_label
            current_label += 1
        
        label = label_map[class_name]
        print(f"ğŸ·ï¸  Etiket: '{class_name}' â†’ {label}")
        
        # Aktif ve boÅŸ segmentleri ayÄ±r
        active_segments, idle_segments = extract_segments_with_idle(df)
        
        # Aktif segmentler (komutlar)
        for seg_idx, segment in enumerate(active_segments):
            windows = create_windows(segment)
            if len(windows) > 0:
                all_windows.append(windows)
                all_labels.extend([label] * len(windows))
                print(f"   âœ… Aktif segment {seg_idx+1}: {len(windows)} pencere")
    
    # BoÅŸ sÄ±nÄ±fÄ±nÄ± ekle
    if include_idle:
        # "boÅŸ" sÄ±nÄ±fÄ±nÄ± label_map'e ekle
        label_map["boÅŸ"] = current_label
        idle_label = current_label
        
        print(f"\n{'='*60}")
        print(f"ğŸ’¤ BOÅ SINIFI EKLENIYOR")
        print(f"{'='*60}")
        print(f"ğŸ·ï¸  Etiket: 'boÅŸ' â†’ {idle_label}")
        
        # TÃ¼m CSV dosyalarÄ±ndaki boÅŸ bÃ¶lgeleri topla
        total_idle_windows = 0
        for filename, df, class_name in csv_files:
            print(f"\nğŸ“‚ {filename} - boÅŸ bÃ¶lgeler:")
            _, idle_segments = extract_segments_with_idle(df)
            
            for seg_idx, segment in enumerate(idle_segments):
                windows = create_windows(segment)
                if len(windows) > 0:
                    all_windows.append(windows)
                    all_labels.extend([idle_label] * len(windows))
                    total_idle_windows += len(windows)
                    print(f"   ğŸ’¤ BoÅŸ segment {seg_idx+1}: {len(windows)} pencere")
        
        print(f"\nâœ… Toplam boÅŸ pencere: {total_idle_windows}")
    
    # TÃ¼m window'larÄ± birleÅŸtir
    if all_windows:
        X = np.vstack(all_windows)
        y = np.array(all_labels)
        
        print(f"\n{'='*60}")
        print(f"ğŸ“Š Ã–ZET")
        print(f"{'='*60}")
        print(f"ğŸ“¦ Toplam pencere: {len(X)}")
        print(f"ğŸ“ Pencere ÅŸekli: {X.shape}")
        print(f"\nğŸ·ï¸  SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±:")
        
        reverse_label_map = {v: k for k, v in label_map.items()}
        for label_idx in sorted(reverse_label_map.keys()):
            label_name = reverse_label_map[label_idx]
            count = np.sum(y == label_idx)
            percentage = (count / len(y)) * 100
            print(f"   {label_name:10s}: {count:5d} pencere ({percentage:5.1f}%)")
        
        return X, y, label_map
    else:
        print("\nâŒ HiÃ§ pencere oluÅŸturulamadÄ±!")
        return None, None, None

def normalize_data(X):
    print("\nNormalizasyon...")
    original_shape = X.shape
    X_flat = X.reshape(X.shape[0], -1)
    scaler = StandardScaler()
    X_normalized_flat = scaler.fit_transform(X_flat)
    X_normalized = X_normalized_flat.reshape(original_shape)
    print(f"   Mean: {X_normalized.mean():.4f}, Std: {X_normalized.std():.4f}")
    return X_normalized, scaler

def visualize_sample(X, y, label_map, sample_idx=0):
    label_names = {v: k for k, v in label_map.items()}
    label_name = label_names[y[sample_idx]]
    fig, axes = plt.subplots(4, 2, figsize=(12, 10))
    fig.suptitle(f'EEG - {label_name}', fontsize=16)
    for idx, (ax, feature_name) in enumerate(zip(axes.flat, EEG_FEATURES)):
        data = X[sample_idx, :, idx]
        ax.plot(data)
        ax.set_title(feature_name)
        ax.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, 'sample_eeg_window.png'), dpi=150)
    print("   âœ… Grafik kaydedildi")
    plt.close()

def save_data(X, y, label_map):
    np.save(os.path.join(OUTPUT_DIR, 'X.npy'), X)
    np.save(os.path.join(OUTPUT_DIR, 'y.npy'), y)
    with open(os.path.join(OUTPUT_DIR, 'label_map.json'), 'w', encoding='utf-8') as f:
        json.dump(label_map, f, indent=2, ensure_ascii=False)
    print(f"\n   âœ… X.npy: {X.shape}")
    print(f"   âœ… y.npy: {y.shape}")
    print(f"   âœ… label_map.json kaydedildi")

def main():
    print("\n" + "="*60)
    print("ğŸ§  EEG VERI Ã–N Ä°ÅLEME - 3 SINIF SÄ°STEMÄ° (BOÅ SINIFI YOK)")
    print("="*60)
    print("ğŸ“‚ Veri dizinleri:")
    for d in DATA_DIRS:
        if os.path.exists(d):
            print(f"   âœ… {d}")
        else:
            print(f"   âš ï¸  {d} (bulunamadÄ±)")
    
    print("\nâš ï¸  NOT: BoÅŸ sÄ±nÄ±fÄ± DAHIL EDÄ°LMEYECEK!")
    print("   â†’ Sadece aktif komutlar: araba, yukarÄ±, aÅŸaÄŸÄ±")
    print("   â†’ BoÅŸ bÃ¶lgeler atlanacak")
    
    csv_files = load_csv_files(DATA_DIRS)
    if not csv_files:
        print("\nâŒ CSV dosyasÄ± bulunamadÄ±!")
        return
    
    X, y, label_map = process_all_data(csv_files, include_idle=False)
    if X is None:
        print("\nâŒ Veri iÅŸleme baÅŸarÄ±sÄ±z!")
        return
    
    X_normalized, scaler = normalize_data(X)
    visualize_sample(X_normalized, y, label_map, 0)
    save_data(X_normalized, y, label_map)
    
    print("\n" + "="*60)
    print("âœ… TAMAMLANDI!")
    print("="*60)
    print(f"ğŸ“‚ Ã‡Ä±ktÄ±: {OUTPUT_DIR}")
    print("ğŸ¯ Åimdi modeli eÄŸitin: python3 train_model.py")
    print("="*60 + "\n")

if __name__ == "__main__":
    main()
